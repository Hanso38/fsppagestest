{
    "docs": [
        {
            "location": "/", 
            "text": "TorQ Demo Pack\n\n\n\n\n\n\n\n\n\n\nThe purpose of the TorQ Demo Pack is to set up an example TorQ\ninstallation and to show how applications can be built and deployed on\ntop of the TorQ framework. The example installation contains all the key\nfeatures of a production data capture installation, including\npersistence and resilience. The demo pack includes:\n\n\n\n\n\n\na dummy data feed\n\n\n\n\n\n\na resilient kdb+ stack to persist data to disk and to allow querying\n    across real time data and historic data\n\n\n\n\n\n\nbasic monitoring with notifications via email\n\n\n\n\n\n\nautomated report generation\n\n\n\n\n\n\nOnce started, TorQ will generate dummy data and push it into an\nin-memory real-time database. It will persist this data to disk every\nday at midnight. The system will operate 24*7 and remove old files over\ntime.\n\n\nFurther information about each feature can be found in the \nTorQ\nManual\n.\n\n\nemail:\n \nsupport@aquaq.co.uk\n\n\nweb:\nwww.aquaq.co.uk", 
            "title": "Home"
        }, 
        {
            "location": "/#torq-demo-pack", 
            "text": "The purpose of the TorQ Demo Pack is to set up an example TorQ\ninstallation and to show how applications can be built and deployed on\ntop of the TorQ framework. The example installation contains all the key\nfeatures of a production data capture installation, including\npersistence and resilience. The demo pack includes:    a dummy data feed    a resilient kdb+ stack to persist data to disk and to allow querying\n    across real time data and historic data    basic monitoring with notifications via email    automated report generation    Once started, TorQ will generate dummy data and push it into an\nin-memory real-time database. It will persist this data to disk every\nday at midnight. The system will operate 24*7 and remove old files over\ntime.  Further information about each feature can be found in the  TorQ\nManual .  email:   support@aquaq.co.uk  web: www.aquaq.co.uk", 
            "title": "TorQ Demo Pack"
        }, 
        {
            "location": "/gettingstarted/", 
            "text": "Getting Started\n\n\nRequirements\n\n\nThe TorQ Finance Starter Pack will run on Windows, Linux or OSX. It\ncontains a small initial database of 130MB. As the system runs, data is\nfed in and written out to disk. We recommend that it is installed with\nat least 2GB of free disk space, on a system with at least 4GB of RAM.\nChrome and Firefox are the supported web browsers.\n\n\nIt is assumed that most users will be running with the free 32-bit\nversion of kdb+. TorQ and the TorQ demo pack will run in exactly the\nsame way on both the 32-bit and 64-bit versions of kdb+.\n\n\nInstallation and Configuration\n\n\nInstallation\n\n\n\n\n\n\nDownload and install kdb+ from \nKx Systems\n\n\n\n\n\n\nDownload the main TorQ codebase from\n    \nhere\n\n\n\n\n\n\nDownload the TorQ Finance Starter Pack from\n    \nhere\n[\n\n\n\n\n\n\nUnzip the TorQ package\n\n\n\n\n\n\nUnzip the Demo Pack over the top of the main TorQ package\n\n\n\n\n\n\nConfiguration\n\n\nThere are additional optional configuration steps depending on whether\nyou want to run TorQ across multiple machines and whether you wish to\ngenerate emails from it. Note that if you are sending emails from an\nemail account which requires SSL authentication from Windows (e.g.\nHotmail, Gmail) then there are some additional steps outlined in the\nmain TorQ document which should be followed. To run TorQ across machines\nyou will need to:\n\n\n\n\nModify config/process.csv to specify the host name of the machine\n    where the process runs. In the \u201chost\u201d column of the csv file, input\n    the hostname or IP address\n\n\n\n\nIf you wish to generate emails from the system you will additionally\nhave to:\n\n\n\n\n\n\nModify DEMOEMAILRECEIVER environment variable at the top of\n    start_torq_demo.sh, start_torq_demo_osx.sh or\n    start_torq_demo.bat\n\n\n\n\n\n\nAdd the email server details in config/settings/default.q. You will\n    need to specify the email server URL, username and password. An\n    example is:\n\n\n// configuration for default mail server\n\\d .email\nenabled:1b\nurl:`$\"smtp://smtp.email.net:80\"        // url of email server\nuser:`$\"testaccount@aquaq.co.uk\"        // user account to use to send emails\npassword:`$\"testkdb\"                    // password for user account\n\n\n\n\n\n\n\nNote that on Windows there may be pop up warnings about missing\nlibraries. These should be resolved by sourcing the correct libraries.\n\n\nStart Up\n\n\nWindows\n\n\nWindows users should use start_torq_demo.bat to start the system, and\nstop_torq_demo.bat to stop it. start_torq_demo.bat will produce a\nseries of command prompt. Each one of these is a TorQ process.\n\n\n\n\nWindows users should note that on some windows installations the\nprocesses sometimes fail to start correctly and become blocked. The\nissue appears to be how the processes connect to each other with\nconnection timeouts not being executed correctly. During testing, we\nobsverved this behaviour on two different windows installations though\ncould not narrow it down to a specific hardware/windows/kdb+ version\nissue. Most versions of windows ran correctly every time (as did all\nversions of Linux/OSX).\n\n\nLinux and OSX\n\n\nLinux users should use start_torq_demo.sh to start the system, and\nstop_torq_demo.sh to stop it. OSX users should use\nstart_torq_demo_osx.sh to start the system, and stop_torq_demo.sh\nto stop it. The only difference between the respective start scripts is\nhow the library path environment variable is set. The processes will\nstart in the background but can be seen using a ps command, such as\n\n\naquaq\n ps -ef | grep 'torq\\|tickerplant' \naquaq    4810 16777  0 15:56 pts/34   00:00:00 grep torq\\|tickerplant\naquaq   25465     1  0 13:05 pts/34   00:00:05 q torq.q -load code/processes/discovery.q -stackid 6000 -proctype discovery -procname discovery1 -U config/passwords/accesslist.txt -localtime\naquaq   25466     1  0 13:05 pts/34   00:00:29 q tickerplant.q database hdb -stackid 6000 -proctype tickerplant -procname tickerplant1 -U config/passwords/accesslist.txt -localtime\naquaq   25478     1  0 13:05 pts/34   00:00:17 q torq.q -load code/processes/rdb.q -stackid 6000 -proctype rdb -procname rdb1  -U config/passwords/accesslist.txt -localtime -g 1 -T 30\naquaq   25479     1  0 13:05 pts/34   00:00:04 q torq.q -load hdb/database -stackid 6000 -proctype hdb -procname hdb1 -U config/passwords/accesslist.txt -localtime -g 1 -T 60 -w 4000\naquaq   25480     1  0 13:05 pts/34   00:00:05 q torq.q -load hdb/database -stackid 6000 -proctype hdb -procname hdb1 -U config/passwords/accesslist.txt -localtime -g 1 -T 60 -w 4000\naquaq   25481     1  0 13:05 pts/34   00:00:06 q torq.q -load code/processes/gateway.q -stackid 6000 -proctype gateway -procname gateway1 -U config/passwords/accesslist.txt -localtime -g 1 -w 4000\naquaq   25482     1  0 13:05 pts/34   00:00:06 q torq.q -load code/processes/monitor.q -stackid 6000 -proctype monitor -procname monitor1 -localtime\naquaq   25483     1  0 13:05 pts/34   00:00:07 q torq.q -load code/processes/reporter.q -stackid 6000 -proctype reporter -procname reporter1 -U config/passwords/accesslist.txt -localtime\naquaq   25484     1  0 13:05 pts/34   00:00:04 q torq.q -load code/processes/housekeeping.q -stackid 6000 -proctype housekeeping -procname housekeeping1 -U config/passwords/accesslist.txt -localtime\naquaq   25485     1  0 13:05 pts/34   00:00:05 q torq.q -load code/processes/wdb.q -stackid 6000 -proctype sort -procname sort1 -U config/passwords/accesslist.txt -localtime -g 1\naquaq   25486     1  0 13:05 pts/34   00:00:13 q torq.q -load code/processes/wdb.q -stackid 6000 -proctype wdb -procname wdb1  -U config/passwords/accesslist.txt -localtime -g 1\naquaq   25547     1  0 13:05 pts/34   00:00:13 q torq.q -load tick/feed.q -stackid 6000 -proctype feed -procname feed1 -localtime\n\n\n\nCheck If the System Is Running\n\n\nTorQ includes a basic monitoring application with a web interface,\nserved up directly from the q process. The monitor checks if each\nprocess is heartbeating, and will display error messages which are\npublished to it by the other processes. New errors are highlighted,\nalong with processes which have stopped heartbeating.\n\n\n\n\nThe monitor UI can be accessed at the address\nhttp://hostname:monitorport/.non?monitorui where hostname is the\nhostname or IP address of the server running the monitor process, and\nmonitor port is the port. The default monitor port is 6009. Note that\nthe hostname resolution for the websocket connection doesn\u2019t always\nhappen correctly- sometimes it is the IP address and sometimes the\nhostname, so please try both. To see exactly what it is being returned\nas, open a new q session on the same machine and run:\n\n\nq)ss[html;\"KDBCONNECT\"] _ html:`::6009:admin:admin \"monitorui[]\"\n\"KDBCONNECT.init(\\\"server.aquaq.co.uk\\\",6009);\\n\n/script\n\\n    \n/body\n\\n\n/html\n\\n\"\n\n\n\nConnecting To A Running Process\n\n\nAny of the following can be used to easily interrogate a running q\nprocess.\n\n\n\n\n\n\nanother q process, by opening a connection and sending commands\n\n\n\n\n\n\nqcon\n\n\n\n\n\n\nan IDE\n\n\n\n\n\n\nThe remainder of this document will use either qcon or an IDE. Each\nprocess is password protected but the user:password combination of\nadmin:admin will allow access.\n\n\nTesting Emails\n\n\nIf you have set up emailing, you can test is using the .email.test\nfunction (from any process). This takes a single parameter of the email\naddress to send a test email to. It returns the size of the email sent\nin bytes upon success, or -1 for failure.\n\n\naquaq$ qcon :6002:admin:admin\n:6002\n.email.test[`$\"testemail@gmail.com\"]                                                                                                                                                        \n16831i\n\n\n\nTo extract more information from the email sending process, set\n.email.debug to 2i.\n\n\n:6002\n.email.debug:2i                                                                                                                                                                                 \n:6002\n.email.test[`$\"testemail@gmail.com\"]                                                                                                                                                        \n16831i\n\n\n\nTrouble Shooting\n\n\nThe system starts processes on ports in the range 6000 to 6014. If there\nare processes already running on these ports there will be a port clash-\nchange the port used in both the start script and in the process.csv\nfile.\n\n\nAll the processes logs to the $KDBLOG directory. In general each\nprocess writes three logs: a standard out log, a standard error log and\na usage log (the queries which have been run against the pro cess\nremotely). Check these log files for errors.\n\n\nDebugging\n\n\nThe easiest way to debug a process is to run it in the foreground. By\ndefault, TorQ will redirect standard out and standard error to log files\non disk. To debug a process, start it on the command line (either the\ncommand prompt on Windows, or a terminal session on Linux or OSX) using\nthe start up line from the appropriate launch script. Supply the -debug\ncommand line parameter to stop it redirecting output to log files on\ndisk.\n\n\nIf the process hits an error on startup it will exit. To avoid this, use\neither -stop or -trap command line flag. -stop will cause the process to\nstop at the error, -trap will cause it to trap it and continue loading.\nAn example is below. This query should be run from within the directory\nyou have extracted TorQ and the TorQ Finance Starter Pack to.\n\n\nq torq.q -load code/processes/rdb.q -stackid 6000 -proctype rdb -procname rdb1 -U config/passwords/accesslist.txt -localtime -g 1 -T 30 -debug -stop\n\n\n\nFile Structure\n\n\nThe file structure can be seen below.\n\n\n|-- AquaQTorQFinanceStarterPack.pdf\n|-- LICENSE\n|-- README.md\n|-- appconfig\n|   `-- settings        \n- modified settings for each process\n|       |-- compression.q\n|       |-- feed.q\n|       |-- gateway.q\n|       |-- killtick.q\n|       |-- monitor.q\n|       |-- rdb.q\n|       |-- sort.q\n|       |-- tickerplant.q\n|       `-- wdb.q\n|-- code\n|   |-- common\n|   |   `-- u.q         \n- kdb+ tick pubsub script\n|   |-- hdb         \n- extra functions loaded by hdb procs\n|   |   `-- examplequeries.q\n|   |-- processes\n|   |   `-- tickerplant.q\n|   |-- rdb         \n- extra functions loaded by rdb procs\n|   |   `-- examplequeries.q\n|   `-- tick            \n- kdb+ tick\n|       |-- feed.q      \n- dummy feed from code.kx\n|       |-- tick        \n|       |   |-- database.q  \n- schema definition file\n|       |   |-- r.q\n|       |   `-- u.q\n|       `-- tick.q      \n- kdb+ tick\n|-- config\n|   |-- application.txt     \n- TorQ demo pack banner\n|   |-- compressionconfig.csv   \n- modified compression config\n|   |-- housekeeping.csv    \n|   |-- passwords\n|   |   |-- accesslist.txt  \n- list of user:pass who can connect to proccesses\n|   |   `-- feed.txt        \n- password file used by feed for connections\n|   |-- process.csv     \n- definition of type/name of each process\n|   `-- reporter.csv        \n- modified config for reporter\n|-- hdb             \n- example hdb data\n|   `-- database\n|       |-- 2015.01.07\n|       |-- 2015.01.08\n|       `-- sym\n|-- setenv.sh           \n- set environment variables\n|-- start_torq_demo.bat     \n- start and stop scripts\n|-- start_torq_demo.sh\n|-- start_torq_demo_osx.sh\n|-- stop_torq_demo.bat\n`-- stop_torq_demo.sh\n\n\n\nThe Demo Pack consists of:\n\n\n\n\n\n\na slightly modified version of kdb+tick from Kx Systems\n\n\n\n\n\n\nan example set of historic data\n\n\n\n\n\n\nconfiguration changes for base TorQ\n\n\n\n\n\n\nadditional queries to run on the RDB and HDB\n\n\n\n\n\n\nstart and stop scripts\n\n\n\n\n\n\nMake It Your Own\n\n\nThe system is production ready. To customize it for a specific data set,\nmodify the schema file and replace the feed process with a feed of data\nfrom a live system.", 
            "title": "Getting Started"
        }, 
        {
            "location": "/gettingstarted/#getting-started", 
            "text": "", 
            "title": "Getting Started"
        }, 
        {
            "location": "/gettingstarted/#requirements", 
            "text": "The TorQ Finance Starter Pack will run on Windows, Linux or OSX. It\ncontains a small initial database of 130MB. As the system runs, data is\nfed in and written out to disk. We recommend that it is installed with\nat least 2GB of free disk space, on a system with at least 4GB of RAM.\nChrome and Firefox are the supported web browsers.  It is assumed that most users will be running with the free 32-bit\nversion of kdb+. TorQ and the TorQ demo pack will run in exactly the\nsame way on both the 32-bit and 64-bit versions of kdb+.", 
            "title": "Requirements"
        }, 
        {
            "location": "/gettingstarted/#installation-and-configuration", 
            "text": "", 
            "title": "Installation and Configuration"
        }, 
        {
            "location": "/gettingstarted/#installation", 
            "text": "Download and install kdb+ from  Kx Systems    Download the main TorQ codebase from\n     here    Download the TorQ Finance Starter Pack from\n     here [    Unzip the TorQ package    Unzip the Demo Pack over the top of the main TorQ package", 
            "title": "Installation"
        }, 
        {
            "location": "/gettingstarted/#configuration", 
            "text": "There are additional optional configuration steps depending on whether\nyou want to run TorQ across multiple machines and whether you wish to\ngenerate emails from it. Note that if you are sending emails from an\nemail account which requires SSL authentication from Windows (e.g.\nHotmail, Gmail) then there are some additional steps outlined in the\nmain TorQ document which should be followed. To run TorQ across machines\nyou will need to:   Modify config/process.csv to specify the host name of the machine\n    where the process runs. In the \u201chost\u201d column of the csv file, input\n    the hostname or IP address   If you wish to generate emails from the system you will additionally\nhave to:    Modify DEMOEMAILRECEIVER environment variable at the top of\n    start_torq_demo.sh, start_torq_demo_osx.sh or\n    start_torq_demo.bat    Add the email server details in config/settings/default.q. You will\n    need to specify the email server URL, username and password. An\n    example is:  // configuration for default mail server\n\\d .email\nenabled:1b\nurl:`$\"smtp://smtp.email.net:80\"        // url of email server\nuser:`$\"testaccount@aquaq.co.uk\"        // user account to use to send emails\npassword:`$\"testkdb\"                    // password for user account    Note that on Windows there may be pop up warnings about missing\nlibraries. These should be resolved by sourcing the correct libraries.", 
            "title": "Configuration"
        }, 
        {
            "location": "/gettingstarted/#start-up", 
            "text": "", 
            "title": "Start Up"
        }, 
        {
            "location": "/gettingstarted/#windows", 
            "text": "Windows users should use start_torq_demo.bat to start the system, and\nstop_torq_demo.bat to stop it. start_torq_demo.bat will produce a\nseries of command prompt. Each one of these is a TorQ process.   Windows users should note that on some windows installations the\nprocesses sometimes fail to start correctly and become blocked. The\nissue appears to be how the processes connect to each other with\nconnection timeouts not being executed correctly. During testing, we\nobsverved this behaviour on two different windows installations though\ncould not narrow it down to a specific hardware/windows/kdb+ version\nissue. Most versions of windows ran correctly every time (as did all\nversions of Linux/OSX).", 
            "title": "Windows"
        }, 
        {
            "location": "/gettingstarted/#linux-and-osx", 
            "text": "Linux users should use start_torq_demo.sh to start the system, and\nstop_torq_demo.sh to stop it. OSX users should use\nstart_torq_demo_osx.sh to start the system, and stop_torq_demo.sh\nto stop it. The only difference between the respective start scripts is\nhow the library path environment variable is set. The processes will\nstart in the background but can be seen using a ps command, such as  aquaq  ps -ef | grep 'torq\\|tickerplant' \naquaq    4810 16777  0 15:56 pts/34   00:00:00 grep torq\\|tickerplant\naquaq   25465     1  0 13:05 pts/34   00:00:05 q torq.q -load code/processes/discovery.q -stackid 6000 -proctype discovery -procname discovery1 -U config/passwords/accesslist.txt -localtime\naquaq   25466     1  0 13:05 pts/34   00:00:29 q tickerplant.q database hdb -stackid 6000 -proctype tickerplant -procname tickerplant1 -U config/passwords/accesslist.txt -localtime\naquaq   25478     1  0 13:05 pts/34   00:00:17 q torq.q -load code/processes/rdb.q -stackid 6000 -proctype rdb -procname rdb1  -U config/passwords/accesslist.txt -localtime -g 1 -T 30\naquaq   25479     1  0 13:05 pts/34   00:00:04 q torq.q -load hdb/database -stackid 6000 -proctype hdb -procname hdb1 -U config/passwords/accesslist.txt -localtime -g 1 -T 60 -w 4000\naquaq   25480     1  0 13:05 pts/34   00:00:05 q torq.q -load hdb/database -stackid 6000 -proctype hdb -procname hdb1 -U config/passwords/accesslist.txt -localtime -g 1 -T 60 -w 4000\naquaq   25481     1  0 13:05 pts/34   00:00:06 q torq.q -load code/processes/gateway.q -stackid 6000 -proctype gateway -procname gateway1 -U config/passwords/accesslist.txt -localtime -g 1 -w 4000\naquaq   25482     1  0 13:05 pts/34   00:00:06 q torq.q -load code/processes/monitor.q -stackid 6000 -proctype monitor -procname monitor1 -localtime\naquaq   25483     1  0 13:05 pts/34   00:00:07 q torq.q -load code/processes/reporter.q -stackid 6000 -proctype reporter -procname reporter1 -U config/passwords/accesslist.txt -localtime\naquaq   25484     1  0 13:05 pts/34   00:00:04 q torq.q -load code/processes/housekeeping.q -stackid 6000 -proctype housekeeping -procname housekeeping1 -U config/passwords/accesslist.txt -localtime\naquaq   25485     1  0 13:05 pts/34   00:00:05 q torq.q -load code/processes/wdb.q -stackid 6000 -proctype sort -procname sort1 -U config/passwords/accesslist.txt -localtime -g 1\naquaq   25486     1  0 13:05 pts/34   00:00:13 q torq.q -load code/processes/wdb.q -stackid 6000 -proctype wdb -procname wdb1  -U config/passwords/accesslist.txt -localtime -g 1\naquaq   25547     1  0 13:05 pts/34   00:00:13 q torq.q -load tick/feed.q -stackid 6000 -proctype feed -procname feed1 -localtime", 
            "title": "Linux and OSX"
        }, 
        {
            "location": "/gettingstarted/#check-if-the-system-is-running", 
            "text": "TorQ includes a basic monitoring application with a web interface,\nserved up directly from the q process. The monitor checks if each\nprocess is heartbeating, and will display error messages which are\npublished to it by the other processes. New errors are highlighted,\nalong with processes which have stopped heartbeating.   The monitor UI can be accessed at the address\nhttp://hostname:monitorport/.non?monitorui where hostname is the\nhostname or IP address of the server running the monitor process, and\nmonitor port is the port. The default monitor port is 6009. Note that\nthe hostname resolution for the websocket connection doesn\u2019t always\nhappen correctly- sometimes it is the IP address and sometimes the\nhostname, so please try both. To see exactly what it is being returned\nas, open a new q session on the same machine and run:  q)ss[html;\"KDBCONNECT\"] _ html:`::6009:admin:admin \"monitorui[]\"\n\"KDBCONNECT.init(\\\"server.aquaq.co.uk\\\",6009);\\n /script \\n     /body \\n /html \\n\"", 
            "title": "Check If the System Is Running"
        }, 
        {
            "location": "/gettingstarted/#connecting-to-a-running-process", 
            "text": "Any of the following can be used to easily interrogate a running q\nprocess.    another q process, by opening a connection and sending commands    qcon    an IDE    The remainder of this document will use either qcon or an IDE. Each\nprocess is password protected but the user:password combination of\nadmin:admin will allow access.", 
            "title": "Connecting To A Running Process"
        }, 
        {
            "location": "/gettingstarted/#testing-emails", 
            "text": "If you have set up emailing, you can test is using the .email.test\nfunction (from any process). This takes a single parameter of the email\naddress to send a test email to. It returns the size of the email sent\nin bytes upon success, or -1 for failure.  aquaq$ qcon :6002:admin:admin\n:6002 .email.test[`$\"testemail@gmail.com\"]                                                                                                                                                        \n16831i  To extract more information from the email sending process, set\n.email.debug to 2i.  :6002 .email.debug:2i                                                                                                                                                                                 \n:6002 .email.test[`$\"testemail@gmail.com\"]                                                                                                                                                        \n16831i", 
            "title": "Testing Emails"
        }, 
        {
            "location": "/gettingstarted/#trouble-shooting", 
            "text": "The system starts processes on ports in the range 6000 to 6014. If there\nare processes already running on these ports there will be a port clash-\nchange the port used in both the start script and in the process.csv\nfile.  All the processes logs to the $KDBLOG directory. In general each\nprocess writes three logs: a standard out log, a standard error log and\na usage log (the queries which have been run against the pro cess\nremotely). Check these log files for errors.", 
            "title": "Trouble Shooting"
        }, 
        {
            "location": "/gettingstarted/#debugging", 
            "text": "The easiest way to debug a process is to run it in the foreground. By\ndefault, TorQ will redirect standard out and standard error to log files\non disk. To debug a process, start it on the command line (either the\ncommand prompt on Windows, or a terminal session on Linux or OSX) using\nthe start up line from the appropriate launch script. Supply the -debug\ncommand line parameter to stop it redirecting output to log files on\ndisk.  If the process hits an error on startup it will exit. To avoid this, use\neither -stop or -trap command line flag. -stop will cause the process to\nstop at the error, -trap will cause it to trap it and continue loading.\nAn example is below. This query should be run from within the directory\nyou have extracted TorQ and the TorQ Finance Starter Pack to.  q torq.q -load code/processes/rdb.q -stackid 6000 -proctype rdb -procname rdb1 -U config/passwords/accesslist.txt -localtime -g 1 -T 30 -debug -stop", 
            "title": "Debugging"
        }, 
        {
            "location": "/gettingstarted/#file-structure", 
            "text": "The file structure can be seen below.  |-- AquaQTorQFinanceStarterPack.pdf\n|-- LICENSE\n|-- README.md\n|-- appconfig\n|   `-- settings         - modified settings for each process\n|       |-- compression.q\n|       |-- feed.q\n|       |-- gateway.q\n|       |-- killtick.q\n|       |-- monitor.q\n|       |-- rdb.q\n|       |-- sort.q\n|       |-- tickerplant.q\n|       `-- wdb.q\n|-- code\n|   |-- common\n|   |   `-- u.q          - kdb+ tick pubsub script\n|   |-- hdb          - extra functions loaded by hdb procs\n|   |   `-- examplequeries.q\n|   |-- processes\n|   |   `-- tickerplant.q\n|   |-- rdb          - extra functions loaded by rdb procs\n|   |   `-- examplequeries.q\n|   `-- tick             - kdb+ tick\n|       |-- feed.q       - dummy feed from code.kx\n|       |-- tick        \n|       |   |-- database.q   - schema definition file\n|       |   |-- r.q\n|       |   `-- u.q\n|       `-- tick.q       - kdb+ tick\n|-- config\n|   |-- application.txt      - TorQ demo pack banner\n|   |-- compressionconfig.csv    - modified compression config\n|   |-- housekeeping.csv    \n|   |-- passwords\n|   |   |-- accesslist.txt   - list of user:pass who can connect to proccesses\n|   |   `-- feed.txt         - password file used by feed for connections\n|   |-- process.csv      - definition of type/name of each process\n|   `-- reporter.csv         - modified config for reporter\n|-- hdb              - example hdb data\n|   `-- database\n|       |-- 2015.01.07\n|       |-- 2015.01.08\n|       `-- sym\n|-- setenv.sh            - set environment variables\n|-- start_torq_demo.bat      - start and stop scripts\n|-- start_torq_demo.sh\n|-- start_torq_demo_osx.sh\n|-- stop_torq_demo.bat\n`-- stop_torq_demo.sh  The Demo Pack consists of:    a slightly modified version of kdb+tick from Kx Systems    an example set of historic data    configuration changes for base TorQ    additional queries to run on the RDB and HDB    start and stop scripts", 
            "title": "File Structure"
        }, 
        {
            "location": "/gettingstarted/#make-it-your-own", 
            "text": "The system is production ready. To customize it for a specific data set,\nmodify the schema file and replace the feed process with a feed of data\nfrom a live system.", 
            "title": "Make It Your Own"
        }, 
        {
            "location": "/architecture/", 
            "text": "Architecture\n\n\nThis section will be used to describe the different features included\nwithin the Finance Starter Pack. For more information on TorQ\nimplementation details you can refer to the \nTorQ\nManual\n,\nreview the code which comprises the system or contact us at\n\n.\n\n\nProcesses\n\n\nThe architecture of the demo system is as below.\n\n\n\n\nFeed\n\n\nThe feed comprises two randomly generated tables, trade and quote. These\ntables have \u2019ticks\u2019 generated by feed.q which are pushed to the\ntickerplant in batches every 200 milliseconds. A large batch is pushed\ninitially then smaller batches after it. The timestamps are local time.\n\n\nThe schema definitions can be seen below and can also be viewed in the\nfile tick/database.q which will be located under the directory you\nextract the TorQ and Starter Pack files to.\n\n\nquote:([]time:`timestamp$(); sym:`g#`symbol$(); bid:`float$(); ask:`float$(); bsize:`long$(); asize:`long$(); mode:`char$(); ex:`symbol$())\ntrade:([]time:`timestamp$(); sym:`g#`symbol$(); price:`float$(); size:`int$(); stop:`boolean$(); cond:`char$(); ex:`symbol$())\n\nmeta quote\nc    | t f a\n-----| -----\ntime | p    \nsym  | s   g\nbid  | f    \nask  | f    \nbsize| j    \nasize| j    \nmode | c    \nex   | s\n\nmeta trade\nc    | t f a\n-----| -----\ntime | p    \nsym  | s   g\nprice| f    \nsize | i    \nstop | b    \ncond | c    \nex   | s\n\n\n\nTickerplant\n\n\nThe tickerplant is the standard kdb+tick tickerplant, with a\nmodification to apply timestamps as timestamp type rather than timespan.\nThe tickerplant log file will be written to hdb/database.\n\n\nRDB\n\n\nThe RDB is a TorQ process which holds data for the current GMT day in\nmemory. Unlike kdb+tick, it does not persist data to disk at end-of-day.\n\n\nWDB and Sort Processes\n\n\nThe WDB is a specilized database process which subscribes to a\ntickerplant and periodically persists data to disk. At EOD this data is\nused to create the HDB partition. It has been configured to operate in\nconjuction with a sorting process which sorts the data it writes to\ndisk.\n\n\nThe sorting process is configured to sort by sym(p#) and time, although\nthis can be configured on a per-table basis in $KDBCONFIG/sort.csv\n\n\nGateway\n\n\nThe gateway connects to the RDB and HDB processes and runs queries\nagainst them. It can access a single process, or join data across\nmultiple processes. It also does load balancing and implements a level\nof resilience by hiding back end process failure from clients. Later in\nthis document in the Have a Pay chapter a number of example queries are\nprovided which demonstrate the functionality of the gateway process\n\n\nReport Engine\n\n\nThe Report Engine runs queries on a schedule against specific back end\nprocesses, including gateways. Once the report is complete the result\ncan be further processed, with available actions such as emailing it out\nor writing it to a file. This has been used to implement some basic\nmonitoring checks and run some end of day reports. The configuration\nfile is in $KDBCONFIG/reporter.csv.\n\n\nHousekeeping\n\n\nThe housekeeping process is used to maintain some of the files written\nto disk by TorQ. In the demo we use it to archive tplogs and both\narchive and eventually remove log files from the TorQ working\ndirectories.\n\n\nThe process has been configured like so:\n\n\nzip,{KDBLOG}/,*.log,,10\nrm,{KDBLOG}/,*.gz,,30\nzip,{KDBHDB}/,database20*,,1\n\n\n\nThe first line can be translated to mean \u2019Compress the files in the\nKDBLOG/ path, matching the *.log pattern, excluding no files and\nwhere the files are older than 10 days\u2019\n\n\nCombined with the other lines, the system will compress process logs\nafter 10 days, delete compressed process logs after 30 days and compress\ntplogs after 1 day.\n\n\nThe compression process will check for work to be done everyday at 0200\nlocal time.\n\n\nCompression\n\n\nThe compression process is used to periodically scan the hdb directory\nfor columnar binary files to compress. The compression settings are\ndefined in $KDBCONFIG/compressionconfig.csv. This allows configuration\nof compression parameters on a per table, column and age basis.\n\n\nIt is intended to be used with a scheduling program like cron. By\ndefault it is a transient process as it will start up, check for files\nto compress, does any work required and then dies.\n\n\nDiscovery\n\n\nThe discovery process is used by the other processes to locate other\nprocesses of interest, and register their own capabilities.\n\n\nMonitor\n\n\nThe monitor process is a basic monitoring process to show process\navaiability via heartbeating, and to display error messages published by\nother processes.\n\n\nWhat Advantages Does This Give Me?\n\n\nA standard kdb+tick set up is great for a lot of installations but some\ncustomers have modified it substantially to fit their needs.\n\n\nEnd Of Day\n\n\nIn a standard kdb+tick setup, the end-of-day event is time consuming and\nthe data is unavailable as it is written from the RDB memory to the HDB\ndisk. With the above setup, this outage is minimized in the following\nways:\n\n\n\n\n\n\nFaster end-of-day as data is written periodically to disk throughout\n    the day\n\n\n\n\n\n\nNo back-pressure (slow subscriber problem) on the tickerplant as the\n    RDB doesn\u2019t write to disk, and the WDB doesn\u2019t do the time consuming\n    sort on the data\n\n\n\n\n\n\n\u201cYesterday\u2019s\u201d data is available in the RDB until the end-of-day\n    operation is complete, meaning no data outage\n\n\n\n\n\n\nGateway: Resilience, Load Balancing and Parallel Access\n\n\nkdb+tick doesn\u2019t include a gateway as standard. There are some examples\non code.kx, but production gateways are generally non trivial to write.\nThe TorQ gateway ensures\n\n\n\n\n\n\nBackend processes can be replicated as required. If one process\n    fails, another will take over transparently to the client\n\n\n\n\n\n\nNew processes can be started intraday and will be automatically\n    available via Discovery Service notifications\n\n\n\n\n\n\nQueries are run in parallel and load balanced across back end\n    processes- multiple clients can query at once\n\n\n\n\n\n\nSupportability\n\n\nTorQ adds a layer of standard tools to aid system supportability on top\nof kdb+tick.\n\n\n\n\n\n\nCommon directories for loading code in a fault tolerant way\n\n\n\n\n\n\nOutput and error log messages are timestamped and standardized\n\n\n\n\n\n\nLog messages can be published to external applications\n\n\n\n\n\n\nAll client queries are logged and timed, and can be externally\n    published\n\n\n\n\n\n\nMonitoring checks are incorporated\n\n\n\n\n\n\nEmail notifications are incorporated\n\n\n\n\n\n\nHousekeeping automatically executed", 
            "title": "Architecture"
        }, 
        {
            "location": "/architecture/#architecture", 
            "text": "This section will be used to describe the different features included\nwithin the Finance Starter Pack. For more information on TorQ\nimplementation details you can refer to the  TorQ\nManual ,\nreview the code which comprises the system or contact us at .", 
            "title": "Architecture"
        }, 
        {
            "location": "/architecture/#processes", 
            "text": "The architecture of the demo system is as below.", 
            "title": "Processes"
        }, 
        {
            "location": "/architecture/#feed", 
            "text": "The feed comprises two randomly generated tables, trade and quote. These\ntables have \u2019ticks\u2019 generated by feed.q which are pushed to the\ntickerplant in batches every 200 milliseconds. A large batch is pushed\ninitially then smaller batches after it. The timestamps are local time.  The schema definitions can be seen below and can also be viewed in the\nfile tick/database.q which will be located under the directory you\nextract the TorQ and Starter Pack files to.  quote:([]time:`timestamp$(); sym:`g#`symbol$(); bid:`float$(); ask:`float$(); bsize:`long$(); asize:`long$(); mode:`char$(); ex:`symbol$())\ntrade:([]time:`timestamp$(); sym:`g#`symbol$(); price:`float$(); size:`int$(); stop:`boolean$(); cond:`char$(); ex:`symbol$())\n\nmeta quote\nc    | t f a\n-----| -----\ntime | p    \nsym  | s   g\nbid  | f    \nask  | f    \nbsize| j    \nasize| j    \nmode | c    \nex   | s\n\nmeta trade\nc    | t f a\n-----| -----\ntime | p    \nsym  | s   g\nprice| f    \nsize | i    \nstop | b    \ncond | c    \nex   | s", 
            "title": "Feed"
        }, 
        {
            "location": "/architecture/#tickerplant", 
            "text": "The tickerplant is the standard kdb+tick tickerplant, with a\nmodification to apply timestamps as timestamp type rather than timespan.\nThe tickerplant log file will be written to hdb/database.", 
            "title": "Tickerplant"
        }, 
        {
            "location": "/architecture/#rdb", 
            "text": "The RDB is a TorQ process which holds data for the current GMT day in\nmemory. Unlike kdb+tick, it does not persist data to disk at end-of-day.", 
            "title": "RDB"
        }, 
        {
            "location": "/architecture/#wdb-and-sort-processes", 
            "text": "The WDB is a specilized database process which subscribes to a\ntickerplant and periodically persists data to disk. At EOD this data is\nused to create the HDB partition. It has been configured to operate in\nconjuction with a sorting process which sorts the data it writes to\ndisk.  The sorting process is configured to sort by sym(p#) and time, although\nthis can be configured on a per-table basis in $KDBCONFIG/sort.csv", 
            "title": "WDB and Sort Processes"
        }, 
        {
            "location": "/architecture/#gateway", 
            "text": "The gateway connects to the RDB and HDB processes and runs queries\nagainst them. It can access a single process, or join data across\nmultiple processes. It also does load balancing and implements a level\nof resilience by hiding back end process failure from clients. Later in\nthis document in the Have a Pay chapter a number of example queries are\nprovided which demonstrate the functionality of the gateway process", 
            "title": "Gateway"
        }, 
        {
            "location": "/architecture/#report-engine", 
            "text": "The Report Engine runs queries on a schedule against specific back end\nprocesses, including gateways. Once the report is complete the result\ncan be further processed, with available actions such as emailing it out\nor writing it to a file. This has been used to implement some basic\nmonitoring checks and run some end of day reports. The configuration\nfile is in $KDBCONFIG/reporter.csv.", 
            "title": "Report Engine"
        }, 
        {
            "location": "/architecture/#housekeeping", 
            "text": "The housekeeping process is used to maintain some of the files written\nto disk by TorQ. In the demo we use it to archive tplogs and both\narchive and eventually remove log files from the TorQ working\ndirectories.  The process has been configured like so:  zip,{KDBLOG}/,*.log,,10\nrm,{KDBLOG}/,*.gz,,30\nzip,{KDBHDB}/,database20*,,1  The first line can be translated to mean \u2019Compress the files in the\nKDBLOG/ path, matching the *.log pattern, excluding no files and\nwhere the files are older than 10 days\u2019  Combined with the other lines, the system will compress process logs\nafter 10 days, delete compressed process logs after 30 days and compress\ntplogs after 1 day.  The compression process will check for work to be done everyday at 0200\nlocal time.", 
            "title": "Housekeeping"
        }, 
        {
            "location": "/architecture/#compression", 
            "text": "The compression process is used to periodically scan the hdb directory\nfor columnar binary files to compress. The compression settings are\ndefined in $KDBCONFIG/compressionconfig.csv. This allows configuration\nof compression parameters on a per table, column and age basis.  It is intended to be used with a scheduling program like cron. By\ndefault it is a transient process as it will start up, check for files\nto compress, does any work required and then dies.", 
            "title": "Compression"
        }, 
        {
            "location": "/architecture/#discovery", 
            "text": "The discovery process is used by the other processes to locate other\nprocesses of interest, and register their own capabilities.", 
            "title": "Discovery"
        }, 
        {
            "location": "/architecture/#monitor", 
            "text": "The monitor process is a basic monitoring process to show process\navaiability via heartbeating, and to display error messages published by\nother processes.", 
            "title": "Monitor"
        }, 
        {
            "location": "/architecture/#what-advantages-does-this-give-me", 
            "text": "A standard kdb+tick set up is great for a lot of installations but some\ncustomers have modified it substantially to fit their needs.", 
            "title": "What Advantages Does This Give Me?"
        }, 
        {
            "location": "/architecture/#end-of-day", 
            "text": "In a standard kdb+tick setup, the end-of-day event is time consuming and\nthe data is unavailable as it is written from the RDB memory to the HDB\ndisk. With the above setup, this outage is minimized in the following\nways:    Faster end-of-day as data is written periodically to disk throughout\n    the day    No back-pressure (slow subscriber problem) on the tickerplant as the\n    RDB doesn\u2019t write to disk, and the WDB doesn\u2019t do the time consuming\n    sort on the data    \u201cYesterday\u2019s\u201d data is available in the RDB until the end-of-day\n    operation is complete, meaning no data outage", 
            "title": "End Of Day"
        }, 
        {
            "location": "/architecture/#gateway-resilience-load-balancing-and-parallel-access", 
            "text": "kdb+tick doesn\u2019t include a gateway as standard. There are some examples\non code.kx, but production gateways are generally non trivial to write.\nThe TorQ gateway ensures    Backend processes can be replicated as required. If one process\n    fails, another will take over transparently to the client    New processes can be started intraday and will be automatically\n    available via Discovery Service notifications    Queries are run in parallel and load balanced across back end\n    processes- multiple clients can query at once", 
            "title": "Gateway: Resilience, Load Balancing and Parallel Access"
        }, 
        {
            "location": "/architecture/#supportability", 
            "text": "TorQ adds a layer of standard tools to aid system supportability on top\nof kdb+tick.    Common directories for loading code in a fault tolerant way    Output and error log messages are timestamped and standardized    Log messages can be published to external applications    All client queries are logged and timed, and can be externally\n    published    Monitoring checks are incorporated    Email notifications are incorporated    Housekeeping automatically executed", 
            "title": "Supportability"
        }, 
        {
            "location": "/play/", 
            "text": "Have a Play\n\n\nGateway\n\n\nQueries\n\n\nSome example queries have been implemented on the RDB an HDB processes.\nThese are defined in $KDBCODE/rdb/examplequeries.q and\n$KDBCODE/hdb/examplequeries.q. These can be run directly on the\nprocesses themselves, or from the gateway which will join the results if\nquerying across processes. To test, connect to the gateway process\nrunning on port 6007 from q process, qcon or from an IDE. An example is\nshown below running from an IDE.\n\n\n\n\nExample queries are listed below.\n\n\n// From the gateway, run a query on the RDB\n.gw.syncexec[\"select sum size by sym from trade\";`rdb]\n\n// Run a query on the HDB\n.gw.syncexec[\"select count i by date from trade\";`hdb]\n\n// Run a freeform time bucketed query and join the results across the RDB and HDB\n// Note that this is generally bad practice as the HDB query doesn't contain a date clause\n.gw.syncexec[\"select sum size, max price by 0D00:05 xbar time from trade where sym=`IBM\";`hdb`rdb]\n\n// Run a query across the RDB and HDB which uses a different join function to add the data from both \n.gw.syncexecj[\"select sum size by sym from trade\";`rdb`hdb;sum]\n\n// Run the pre-defined functions - these are implemented to query the RDB and HDB as efficiently as possible\n\n// Run a bucketed HLOC query, both as a string and in functional form\n.gw.syncexec[\"hloc[2015.01.07;.z.d;0D12]\";`hdb`rdb]\n.gw.syncexec[(`hloc;2015.01.07;.z.d;0D12);`hdb`rdb]\n\n// Run a count by sym across a date range, and add the results. \n// Run both as a string and in functional from\n.gw.syncexecj[\"countbysym[2015.01.07;.z.d]\";`hdb`rdb;sum]\n.gw.syncexecj[(`countbysym;2015.01.07;.z.d);`hdb`rdb;sum]\n\n// Run a gateway query with a bespoke join function to line up results and compare today's data with historic data\n.gw.syncexecj[(`countbysym;2015.01.07;.z.d);`hdb`rdb;{(`sym xkey select sym,histavgsize:size%tradecount from x 0) lj `sym xkey select sym,todayavgsize:size%tradecount from x 1}]\n\n// Send a query for a process type which doesn't exist\n.gw.syncexec[\"select count i by date from trade\";`hdb`rubbish]\n\n// Send a query which fails\n.gw.syncexec[\"1+`a\";`hdb]\n\n\n\nResilience\n\n\nThe gateway handles backend processes failing and restarting. To test\nit:\n\n\n\n\n\n\nManually kill one of the HDB processes (close the process on\n    Windows, use the kill command on Linux or OS X)\n\n\n\n\n\n\nRun one of the gateway queries which uses an HDB\n\n\n\n\n\n\nKill the remaining HDB process\n\n\n\n\n\n\nRe-run the query- the gateway should return a failure error\n\n\n\n\n\n\nRestart one of the HDB processes. To do this either run the correct\n    individual line from the start script, or run the full start script.\n\n\n\n\n\n\nRe-run the gateway query- it should be successful\n\n\n\n\n\n\nCheck the monitor for changes when killing and restarting processes.\n\n\nLoad Balancing\n\n\nNew processes can be dynamically added and they will register with the\ngateway which will start running queries across them. To test it, create\n3 client q processes which run queries against the gateway as below.\nNote that the code below could be pasted into a q script and run for\neach client.\n\n\n// open a connection\nq)h:hopen `::6007:admin:admin\n// function that will take 5 seconds to run on the HDB\nq)f:{system $[.z.o like \"w*\";\"timeout \";\"sleep \"],string x}\n// function that will query the gateway\nq)g:{(neg h)(`.gw.asyncexec;(f;x); `hdb); h[]}\n// run the query, print the time\nq)sendquery:{-1\"query took \",(string (system\"t g[\",(string r),\"]\")%10*r:1+rand 5),\"% of expected time\";}\nq)do[100;sendquery[]]\n\n\n\nEach client is trying to run a query on the HDB which takes 5 seconds.\nThere are 3 clients, and only 2 HDB processes sitting behind the\ngateway. Each query will therefore take between 5 and 10 seconds,\ndepending on arrival time. As the number of clients increases, the\naverage time will increase.\n\n\nAssuming the environment variables are set up, a new HDB process can be\nstarted like this:\n\n\nq torq.q -load hdb/database -p 31302 -U config/passwords/accesslist.txt -o 0 -proctype hdb -procname temphdb -debug\n\n\n\nThis will automatically connect to the gateway, and allow more queries\nto be run in parallel.\n\n\nExamine the Logs\n\n\nEach process writes logs to $KDBLOG. These are standard out, standard\nerror, and usage logs. The usage logs are also stored in memory by\ndefault, in the .usage.usage table. The table can be used to analyze\nwhich queries are taking a long time, which users are sending a lot of\nqueries, the memory usage before and after each query, which queries are\nfailing etc.\n\n\nReports\n\n\nThe Reporter process has a set of default \u201creports\u201d configured in\n$KDBCONFIG/reporter.csv. These are:\n\n\n\n\n\n\nA memory check which runs periodically against the RDB and emails an\n    alert if the memory usage goes above a certain size\n\n\n\n\n\n\nA count check which runs periodically against the RDB and emails an\n    alert if a certain number of updates haven\u2019t been received by a\n    certain set of tables within a given period\n\n\n\n\n\n\nA date check which runs periodically against the HDB after\n    end-of-day and raises an alert if the HDB date range isn\u2019t as\n    expected\n\n\n\n\n\n\nAn example end-of-day report which runs against the RDB at a\n    specific time and produces a csv report of high, low, open and close\n    prices per instrument and emails it\n\n\n\n\n\n\nThe same example end-of-day report as above but running against the\n    gateway which then forward it to the RDB\n\n\n\n\n\n\nThe config can be modified to change the reports that are run. Some\nexample modifications would be changing the thresholds at which alerts\nare generated, how often they are run, and what is done with the\nresults. New reports can also be created. The report process will need\nto be restarted to load the new configuration.\n\n\nAccess Control\n\n\nAdding Users\n\n\nFor simplicity each process is password protected using the file\n$KDBCONFIG/passwords/accesslist.txt file. This can be modified to have\ndifferent access lists for each process. To add a new user, add their\nuser:password combination to the file and either restart the process or\nexecute\n\n\nq)\\u\n\n\n\nwithin the process.\n\n\nUser Privileges\n\n\nTorQ possesses utilities for controlling user access in the form of\ndifferent user identities with different access levels. For more\ninformation on how to configure this, see the \u201cMessage Handlers\u201d section\nin the main TorQ document.", 
            "title": "Have a Play"
        }, 
        {
            "location": "/play/#have-a-play", 
            "text": "", 
            "title": "Have a Play"
        }, 
        {
            "location": "/play/#gateway", 
            "text": "", 
            "title": "Gateway"
        }, 
        {
            "location": "/play/#queries", 
            "text": "Some example queries have been implemented on the RDB an HDB processes.\nThese are defined in $KDBCODE/rdb/examplequeries.q and\n$KDBCODE/hdb/examplequeries.q. These can be run directly on the\nprocesses themselves, or from the gateway which will join the results if\nquerying across processes. To test, connect to the gateway process\nrunning on port 6007 from q process, qcon or from an IDE. An example is\nshown below running from an IDE.   Example queries are listed below.  // From the gateway, run a query on the RDB\n.gw.syncexec[\"select sum size by sym from trade\";`rdb]\n\n// Run a query on the HDB\n.gw.syncexec[\"select count i by date from trade\";`hdb]\n\n// Run a freeform time bucketed query and join the results across the RDB and HDB\n// Note that this is generally bad practice as the HDB query doesn't contain a date clause\n.gw.syncexec[\"select sum size, max price by 0D00:05 xbar time from trade where sym=`IBM\";`hdb`rdb]\n\n// Run a query across the RDB and HDB which uses a different join function to add the data from both \n.gw.syncexecj[\"select sum size by sym from trade\";`rdb`hdb;sum]\n\n// Run the pre-defined functions - these are implemented to query the RDB and HDB as efficiently as possible\n\n// Run a bucketed HLOC query, both as a string and in functional form\n.gw.syncexec[\"hloc[2015.01.07;.z.d;0D12]\";`hdb`rdb]\n.gw.syncexec[(`hloc;2015.01.07;.z.d;0D12);`hdb`rdb]\n\n// Run a count by sym across a date range, and add the results. \n// Run both as a string and in functional from\n.gw.syncexecj[\"countbysym[2015.01.07;.z.d]\";`hdb`rdb;sum]\n.gw.syncexecj[(`countbysym;2015.01.07;.z.d);`hdb`rdb;sum]\n\n// Run a gateway query with a bespoke join function to line up results and compare today's data with historic data\n.gw.syncexecj[(`countbysym;2015.01.07;.z.d);`hdb`rdb;{(`sym xkey select sym,histavgsize:size%tradecount from x 0) lj `sym xkey select sym,todayavgsize:size%tradecount from x 1}]\n\n// Send a query for a process type which doesn't exist\n.gw.syncexec[\"select count i by date from trade\";`hdb`rubbish]\n\n// Send a query which fails\n.gw.syncexec[\"1+`a\";`hdb]", 
            "title": "Queries"
        }, 
        {
            "location": "/play/#resilience", 
            "text": "The gateway handles backend processes failing and restarting. To test\nit:    Manually kill one of the HDB processes (close the process on\n    Windows, use the kill command on Linux or OS X)    Run one of the gateway queries which uses an HDB    Kill the remaining HDB process    Re-run the query- the gateway should return a failure error    Restart one of the HDB processes. To do this either run the correct\n    individual line from the start script, or run the full start script.    Re-run the gateway query- it should be successful    Check the monitor for changes when killing and restarting processes.", 
            "title": "Resilience"
        }, 
        {
            "location": "/play/#load-balancing", 
            "text": "New processes can be dynamically added and they will register with the\ngateway which will start running queries across them. To test it, create\n3 client q processes which run queries against the gateway as below.\nNote that the code below could be pasted into a q script and run for\neach client.  // open a connection\nq)h:hopen `::6007:admin:admin\n// function that will take 5 seconds to run on the HDB\nq)f:{system $[.z.o like \"w*\";\"timeout \";\"sleep \"],string x}\n// function that will query the gateway\nq)g:{(neg h)(`.gw.asyncexec;(f;x); `hdb); h[]}\n// run the query, print the time\nq)sendquery:{-1\"query took \",(string (system\"t g[\",(string r),\"]\")%10*r:1+rand 5),\"% of expected time\";}\nq)do[100;sendquery[]]  Each client is trying to run a query on the HDB which takes 5 seconds.\nThere are 3 clients, and only 2 HDB processes sitting behind the\ngateway. Each query will therefore take between 5 and 10 seconds,\ndepending on arrival time. As the number of clients increases, the\naverage time will increase.  Assuming the environment variables are set up, a new HDB process can be\nstarted like this:  q torq.q -load hdb/database -p 31302 -U config/passwords/accesslist.txt -o 0 -proctype hdb -procname temphdb -debug  This will automatically connect to the gateway, and allow more queries\nto be run in parallel.", 
            "title": "Load Balancing"
        }, 
        {
            "location": "/play/#examine-the-logs", 
            "text": "Each process writes logs to $KDBLOG. These are standard out, standard\nerror, and usage logs. The usage logs are also stored in memory by\ndefault, in the .usage.usage table. The table can be used to analyze\nwhich queries are taking a long time, which users are sending a lot of\nqueries, the memory usage before and after each query, which queries are\nfailing etc.", 
            "title": "Examine the Logs"
        }, 
        {
            "location": "/play/#reports", 
            "text": "The Reporter process has a set of default \u201creports\u201d configured in\n$KDBCONFIG/reporter.csv. These are:    A memory check which runs periodically against the RDB and emails an\n    alert if the memory usage goes above a certain size    A count check which runs periodically against the RDB and emails an\n    alert if a certain number of updates haven\u2019t been received by a\n    certain set of tables within a given period    A date check which runs periodically against the HDB after\n    end-of-day and raises an alert if the HDB date range isn\u2019t as\n    expected    An example end-of-day report which runs against the RDB at a\n    specific time and produces a csv report of high, low, open and close\n    prices per instrument and emails it    The same example end-of-day report as above but running against the\n    gateway which then forward it to the RDB    The config can be modified to change the reports that are run. Some\nexample modifications would be changing the thresholds at which alerts\nare generated, how often they are run, and what is done with the\nresults. New reports can also be created. The report process will need\nto be restarted to load the new configuration.", 
            "title": "Reports"
        }, 
        {
            "location": "/play/#access-control", 
            "text": "", 
            "title": "Access Control"
        }, 
        {
            "location": "/play/#adding-users", 
            "text": "For simplicity each process is password protected using the file\n$KDBCONFIG/passwords/accesslist.txt file. This can be modified to have\ndifferent access lists for each process. To add a new user, add their\nuser:password combination to the file and either restart the process or\nexecute  q)\\u  within the process.", 
            "title": "Adding Users"
        }, 
        {
            "location": "/play/#user-privileges", 
            "text": "TorQ possesses utilities for controlling user access in the form of\ndifferent user identities with different access levels. For more\ninformation on how to configure this, see the \u201cMessage Handlers\u201d section\nin the main TorQ document.", 
            "title": "User Privileges"
        }
    ]
}